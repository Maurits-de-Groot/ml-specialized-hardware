# How to reduce costs and improve performance of your Machine Learning (ML) workloads?

In this repo you'll learn how to use [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/) and [AWS Inferentia](https://aws.amazon.com/machine-learning/inferentia/) with [Amazon SageMaker](https://aws.amazon.com/sagemaker/) and [Hugging Face Optimum Neuron](https://huggingface.co/docs/optimum-neuron/index), to optimize your ML workloads! Here you find workshops, tutorials, blog post content, etc. you can use to learn and inspire your own solution.

### Workshops

|Description|
|:-|
|[How to create a spam classifier?](workshops/01_FineTuneSpamClassifier)|
|[How to adapt a pre-trained model to your own business needs and add a conversational interface](workshops/02_DomainAdaptation)|

### Tutorials

|Description|
|:-|
|[inf1 - Extract embeddings from raw text](tutorials/01_EmbeddingsFromTextWithBert)|
|[inf1 - Track objects in video streaming using CV](tutorials/02_ObjectTrackingSageMakerGStreamer)|
|[inf1 - Create a closed question Q&A model](tutorials/03_QuestionAnsweringMachine)|
|[ind2 - Generate images using SD](tutorials/04_ImageGenerationWithStableDiffusion)|
|[inf1 - Answer questions given a context](tutorials/05_FastQuestionAnsweringWithBertQA)|
|[trn1 - Fine-tune a LLM using distributed training](tutorials/06_FinetuneLLMs)|
|[inf2 - Deploy a LLM to HF TGI](tutorials/07_DeployToInferentiaWithTGI)|

### Blog posts content
|Description|
|:-|
|[Llama3-8B Deployment on AWS Inferentia 2 with Amazon EKS and vLLM](blogs/01_LLama3-8B_Inferentia_EKS_vLLM/)|

## Contributing
If you have questions, comments, suggestions, etc. please feel free to cut tickets in this repo.

Also, please refer to the [CONTRIBUTING](CONTRIBUTING.md) document for further details on contributing to this repository.
